{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyOjtOHDLp2HV1lkMcjOlP7O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzOqyylbhp60","executionInfo":{"status":"ok","timestamp":1731220166338,"user_tz":-480,"elapsed":17586,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"d1290875-b69e-4a63-f2b0-d09289722d84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torch torchvision\n","!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoJljcPRoLnL","executionInfo":{"status":"ok","timestamp":1731184385308,"user_tz":-480,"elapsed":5220,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"7e2d6792-7a32-43a6-bad0-59bfae2fc638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.0+cu121)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchvision) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchvision) (3.0.2)\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision torchmetrics tqdm scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjNxkY2t3lWG","executionInfo":{"status":"ok","timestamp":1731188398797,"user_tz":-480,"elapsed":3783,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"036511cd-a9cf-49c6-b53e-82e3eff957e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.2\n"]}]},{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from tqdm import tqdm"],"metadata":{"id":"yBeBCIyIk3ER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from torchvision import transforms\n","from sklearn.preprocessing import LabelEncoder\n","\n","# 载入CIFAR-10数据的工具函数\n","def unpickle(file):\n","    with open(file, 'rb') as fo:\n","        data_dict = pickle.load(fo, encoding='bytes')\n","    return data_dict\n","\n","# 自定义CIFAR-10数据集类\n","class CIFAR10Dataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.data = []\n","        self.labels = []\n","\n","        # 加载训练数据\n","        for i in range(1, 6):  # data_batch_1 to data_batch_5\n","            batch_file = os.path.join(data_dir, f'data_batch_{i}')\n","            batch_dict = unpickle(batch_file)\n","            self.data.append(batch_dict[b'data'])\n","            self.labels.append(batch_dict[b'labels'])\n","\n","        # 合并所有的数据和标签\n","        self.data = np.concatenate(self.data)\n","        self.labels = np.concatenate(self.labels)\n","\n","        # 将数据转换为32x32x3的图像格式\n","        self.data = self.data.reshape((self.data.shape[0], 3, 32, 32))\n","        self.data = self.data.transpose(0, 2, 3, 1)  # 转换为 (batch_size, height, width, channels)\n","\n","        # 标签转为tensor\n","        self.labels = np.array(self.labels)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img = self.data[idx]\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","# 图像预处理\n","data_transform = {\n","    \"train\": transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize([224, 224]),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ]),\n","    \"val\": transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize([224, 224]),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","}\n","\n","# 设置数据路径\n","train_dir = \"/content/drive/MyDrive/Colab Notebooks/EE6483Project/cifar-10/cifar-10-batches-py\"\n","val_dir = \"/content/drive/MyDrive/Colab Notebooks/EE6483Project/cifar-10/cifar-10-batches-py\"  # 可以调整为测试数据集路径\n","\n","# 加载数据集\n","train_dataset = CIFAR10Dataset(data_dir=train_dir, transform=data_transform[\"train\"])\n","val_dataset = CIFAR10Dataset(data_dir=val_dir, transform=data_transform[\"val\"])\n","\n","# 创建数据加载器\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","\n","# 输出数据形状\n","for images, labels in train_loader:\n","    print(images.shape, labels.shape)\n","    break\n"],"metadata":{"id":"opKDGKrAk8Om","executionInfo":{"status":"ok","timestamp":1731220202009,"user_tz":-480,"elapsed":13848,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"09054126-f48f-4ef5-8635-a05ab0b14f13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 3, 224, 224]) torch.Size([16])\n"]}]},{"cell_type":"code","source":["!pip install torchmetrics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhdQatA3xPUl","executionInfo":{"status":"ok","timestamp":1731220353118,"user_tz":-480,"elapsed":2767,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"bdfccf89-6652-4116-f66f-85c650af1285"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cpu)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n","Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.2\n"]}]},{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from tqdm import tqdm\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassAUROC\n","import torch.nn.functional as F  # 确保导入 F 模块\n","\n","# 设置设备\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# 数据加载工具函数\n","def unpickle(file):\n","    with open(file, 'rb') as fo:\n","        data_dict = pickle.load(fo, encoding='bytes')\n","    return data_dict\n","\n","# 自定义CIFAR-10数据集类\n","class CIFAR10Dataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.data = []\n","        self.labels = []\n","\n","        # 加载数据\n","        for i in range(1, 6):\n","            batch_file = os.path.join(data_dir, f'data_batch_{i}')\n","            batch_dict = unpickle(batch_file)\n","            self.data.append(batch_dict[b'data'])\n","            self.labels.append(batch_dict[b'labels'])\n","\n","        # 合并数据和标签\n","        self.data = np.concatenate(self.data)\n","        self.labels = np.concatenate(self.labels)\n","        self.data = self.data.reshape((self.data.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img = self.data[idx]\n","        label = self.labels[idx]\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label\n","\n","# 图像预处理\n","data_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# 加载数据集\n","train_dir = train_dir = \"/content/drive/MyDrive/Colab Notebooks/EE6483Project/cifar-10/cifar-10-batches-py\"\n","train_dataset = CIFAR10Dataset(data_dir=train_dir, transform=data_transform)\n","val_dataset = CIFAR10Dataset(data_dir=train_dir, transform=data_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n","\n","# 定义GoogLeNet模型\n","model = models.googlenet(weights='IMAGENET1K_V1', aux_logits=True)\n","model.fc = nn.Linear(1024, 10)\n","if model.aux1:\n","    model.aux1.fc2 = nn.Linear(model.aux1.fc2.in_features, 10)\n","if model.aux2:\n","    model.aux2.fc2 = nn.Linear(model.aux2.fc2.in_features, 10)\n","model.to(device)\n","\n","# 损失函数和优化器\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","def train_and_evaluate(model, train_loader, val_loader, epochs):\n","    accuracy_metric = MulticlassAccuracy(num_classes=10).to(device)\n","    auroc_metric = MulticlassAUROC(num_classes=10).to(device)\n","\n","    for epoch in range(epochs):\n","        # 训练阶段\n","        model.train()\n","        train_loss, train_correct = 0, 0\n","        y_true_train, y_pred_train, y_prob_train = [], [], []\n","        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\"):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","\n","            if isinstance(outputs, tuple):\n","                logits, aux1, aux2 = outputs\n","                loss = criterion(logits, labels) + 0.3 * criterion(aux1, labels) + 0.3 * criterion(aux2, labels)\n","            else:\n","                logits = outputs\n","                loss = criterion(logits, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            _, predicted = torch.max(logits, 1)\n","            train_correct += (predicted == labels).sum().item()\n","\n","            y_true_train.extend(labels.cpu().numpy())\n","            y_pred_train.extend(predicted.cpu().numpy())\n","\n","            # 获取概率分布用于 AUC 计算\n","            probs = F.softmax(logits, dim=1).detach().cpu().numpy()\n","            y_prob_train.extend(probs)\n","\n","        train_acc = train_correct / len(train_loader.dataset)\n","        train_loss /= len(train_loader)\n","        train_precision = precision_score(y_true_train, y_pred_train, average='macro')\n","        train_recall = recall_score(y_true_train, y_pred_train, average='macro')\n","        train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\n","        train_roc_auc = roc_auc_score(y_true_train, y_prob_train, multi_class='ovr')\n","\n","        print(f\"\\n[Train] Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, \"\n","              f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, \"\n","              f\"F1 Score: {train_f1:.4f}, AUC-ROC: {train_roc_auc:.4f}\")\n","\n","        # 验证阶段\n","        model.eval()\n","        val_loss, val_correct = 0, 0\n","        y_true_val, y_pred_val, y_prob_val = [], [], []\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\"):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","\n","                if isinstance(outputs, tuple):\n","                    logits, aux1, aux2 = outputs\n","                    loss = criterion(logits, labels) + 0.3 * criterion(aux1, labels) + 0.3 * criterion(aux2, labels)\n","                else:\n","                    logits = outputs\n","                    loss = criterion(logits, labels)\n","\n","                val_loss += loss.item()\n","                _, predicted = torch.max(logits, 1)\n","                val_correct += (predicted == labels).sum().item()\n","\n","                y_true_val.extend(labels.cpu().numpy())\n","                y_pred_val.extend(predicted.cpu().numpy())\n","\n","                # 获取概率分布用于 AUC 计算\n","                probs = F.softmax(logits, dim=1).detach().cpu().numpy()\n","                y_prob_val.extend(probs)\n","\n","        val_acc = val_correct / len(val_loader.dataset)\n","        val_loss /= len(val_loader)\n","        val_precision = precision_score(y_true_val, y_pred_val, average='macro')\n","        val_recall = recall_score(y_true_val, y_pred_val, average='macro')\n","        val_f1 = f1_score(y_true_val, y_pred_val, average='macro')\n","        val_roc_auc = roc_auc_score(y_true_val, y_prob_val, multi_class='ovr')\n","\n","        print(f\"[Validation] Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, \"\n","              f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, \"\n","              f\"F1 Score: {val_f1:.4f}, AUC-ROC: {val_roc_auc:.4f}\")\n"],"metadata":{"id":"wksJSSszo3MV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731222960413,"user_tz":-480,"elapsed":990,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"dd2ce8ce-131f-40a8-f296-403586deb6a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"code","source":["train_and_evaluate(model, train_loader, val_loader, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyy1EWt2xqSw","executionInfo":{"status":"ok","timestamp":1731236303935,"user_tz":-480,"elapsed":13341352,"user":{"displayName":"Hasem ndbxj Hdjdnv","userId":"12114095975536990774"}},"outputId":"970cea50-c577-4bf5-dad4-b4bbff3d021c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10 - Training: 100%|██████████| 1563/1563 [16:28<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 1.0973, Accuracy: 0.7981, Precision: 0.7977, Recall: 0.7981, F1 Score: 0.7978, AUC-ROC: 0.9777\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/10 - Validation: 100%|██████████| 1563/1563 [04:43<00:00,  5.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.4296, Accuracy: 0.8533, Precision: 0.8646, Recall: 0.8533, F1 Score: 0.8544, AUC-ROC: 0.9904\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10 - Training: 100%|██████████| 1563/1563 [16:34<00:00,  1.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.6942, Accuracy: 0.8756, Precision: 0.8755, Recall: 0.8756, F1 Score: 0.8756, AUC-ROC: 0.9910\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10 - Validation: 100%|██████████| 1563/1563 [04:25<00:00,  5.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.2554, Accuracy: 0.9100, Precision: 0.9176, Recall: 0.9100, F1 Score: 0.9106, AUC-ROC: 0.9961\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10 - Training: 100%|██████████| 1563/1563 [17:00<00:00,  1.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.5372, Accuracy: 0.9069, Precision: 0.9068, Recall: 0.9069, F1 Score: 0.9069, AUC-ROC: 0.9947\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10 - Validation: 100%|██████████| 1563/1563 [05:22<00:00,  4.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.1681, Accuracy: 0.9433, Precision: 0.9438, Recall: 0.9433, F1 Score: 0.9430, AUC-ROC: 0.9982\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10 - Training: 100%|██████████| 1563/1563 [17:09<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.4317, Accuracy: 0.9256, Precision: 0.9255, Recall: 0.9256, F1 Score: 0.9255, AUC-ROC: 0.9967\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10 - Validation: 100%|██████████| 1563/1563 [04:49<00:00,  5.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.1427, Accuracy: 0.9518, Precision: 0.9524, Recall: 0.9518, F1 Score: 0.9516, AUC-ROC: 0.9988\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10 - Training: 100%|██████████| 1563/1563 [17:07<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.3536, Accuracy: 0.9401, Precision: 0.9400, Recall: 0.9401, F1 Score: 0.9400, AUC-ROC: 0.9978\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10 - Validation: 100%|██████████| 1563/1563 [06:31<00:00,  3.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.1034, Accuracy: 0.9659, Precision: 0.9661, Recall: 0.9659, F1 Score: 0.9658, AUC-ROC: 0.9992\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10 - Training: 100%|██████████| 1563/1563 [17:34<00:00,  1.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.2946, Accuracy: 0.9519, Precision: 0.9519, Recall: 0.9519, F1 Score: 0.9519, AUC-ROC: 0.9985\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10 - Validation: 100%|██████████| 1563/1563 [06:32<00:00,  3.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.0894, Accuracy: 0.9698, Precision: 0.9706, Recall: 0.9698, F1 Score: 0.9699, AUC-ROC: 0.9996\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10 - Training: 100%|██████████| 1563/1563 [16:41<00:00,  1.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.2508, Accuracy: 0.9597, Precision: 0.9597, Recall: 0.9597, F1 Score: 0.9597, AUC-ROC: 0.9990\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10 - Validation: 100%|██████████| 1563/1563 [04:30<00:00,  5.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.0865, Accuracy: 0.9701, Precision: 0.9715, Recall: 0.9701, F1 Score: 0.9703, AUC-ROC: 0.9996\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10 - Training: 100%|██████████| 1563/1563 [15:54<00:00,  1.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.2125, Accuracy: 0.9668, Precision: 0.9668, Recall: 0.9668, F1 Score: 0.9668, AUC-ROC: 0.9993\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10 - Validation: 100%|██████████| 1563/1563 [04:46<00:00,  5.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.2125, Accuracy: 0.9400, Precision: 0.9555, Recall: 0.9400, F1 Score: 0.9423, AUC-ROC: 0.9979\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10 - Training: 100%|██████████| 1563/1563 [18:19<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.1909, Accuracy: 0.9705, Precision: 0.9705, Recall: 0.9705, F1 Score: 0.9705, AUC-ROC: 0.9994\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10 - Validation: 100%|██████████| 1563/1563 [06:33<00:00,  3.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.0399, Accuracy: 0.9873, Precision: 0.9874, Recall: 0.9873, F1 Score: 0.9873, AUC-ROC: 0.9999\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10 - Training: 100%|██████████| 1563/1563 [16:41<00:00,  1.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Train] Loss: 0.1591, Accuracy: 0.9759, Precision: 0.9759, Recall: 0.9759, F1 Score: 0.9759, AUC-ROC: 0.9996\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10 - Validation: 100%|██████████| 1563/1563 [04:26<00:00,  5.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Validation] Loss: 0.0548, Accuracy: 0.9824, Precision: 0.9831, Recall: 0.9824, F1 Score: 0.9826, AUC-ROC: 0.9998\n"]}]}]}